{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d1f6c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Divy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "from collections import Counter\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from tqdm.notebook import tqdm\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53a21d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_ENVIRONMENT = os.getenv(\"PINECONE_ENVIRONMENT\")\n",
    "PINECONE_INDEX_NAME = \"owasp-chatbot-index\"\n",
    "EMBEDDING_DIM = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2873b3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Pinecone client and connecting to index...\n",
      "Successfully connected to Pinecone index 'owasp-chatbot-index'.\n",
      "Index stats: Dimension=768, Total Vectors=2160\n"
     ]
    }
   ],
   "source": [
    "# Update the Pinecone index check section\n",
    "print(\"Initializing Pinecone client and connecting to index...\")\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Connect to the existing Pinecone index\n",
    "try:\n",
    "    # List all indexes and check if our index exists\n",
    "    indexes = pc.list_indexes()\n",
    "    index_names = [index.name for index in indexes.indexes] if hasattr(indexes, 'indexes') else []\n",
    "    \n",
    "    if PINECONE_INDEX_NAME not in index_names:\n",
    "        raise ValueError(f\"Pinecone index '{PINECONE_INDEX_NAME}' does not exist. Please run the data population notebook first.\")\n",
    "    \n",
    "    # Connect to the index\n",
    "    pinecone_index = pc.Index(PINECONE_INDEX_NAME)\n",
    "    print(f\"Successfully connected to Pinecone index '{PINECONE_INDEX_NAME}'.\")\n",
    "    \n",
    "    # Get index stats\n",
    "    index_stats = pinecone_index.describe_index_stats()\n",
    "    print(f\"Index stats: Dimension={index_stats.dimension}, Total Vectors={index_stats.total_vector_count}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"CRITICAL ERROR: Failed to connect to Pinecone index '{PINECONE_INDEX_NAME}'.\")\n",
    "    print(f\"Reason: {e}\")\n",
    "    print(\"Please ensure:\")\n",
    "    print(\"1. Your Pinecone API key is correct\")\n",
    "    print(\"2. The index name is correct\")\n",
    "    print(\"3. The index exists in your Pinecone project\")\n",
    "    print(\"4. Your network connection is stable\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deed4684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available indexes: ['owasp-chatbot-index']\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "pc = pinecone.Pinecone(api_key=PINECONE_API_KEY)\n",
    "print(\"Available indexes:\", [idx.name for idx in pc.list_indexes()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc1aa82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing FINE-TUNED BERT model from ./fine_tuned_owasp_model_advanced...\n",
      "Fine-tuned BERT model loaded successfully.\n",
      "\n",
      "Initializing Pinecone client...\n",
      "\n",
      "Connecting to Pinecone index: owasp-chatbot-index\n",
      "\n",
      "Available indexes in your project:\n",
      "['owasp-chatbot-index']\n",
      "\n",
      "Successfully connected to index: owasp-chatbot-index\n",
      "Index stats: 768 dimensions, 2160 vectors\n",
      "\n",
      "Pinecone connection established successfully!\n"
     ]
    }
   ],
   "source": [
    "model_path = './fine_tuned_owasp_model_advanced'\n",
    "print(f\"Initializing FINE-TUNED BERT model from {model_path}...\")\n",
    "try:\n",
    "    model = SentenceTransformer(model_path)\n",
    "    print(\"Fine-tuned BERT model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading fine-tuned model from {model_path}: {e}\")\n",
    "    print(\"Please ensure you've run Notebook 1 successfully and the model path is correct.\")\n",
    "    print(\"Falling back to default 'all-mpnet-base-v2' model. This will likely reduce accuracy.\")\n",
    "    model = SentenceTransformer('all-mpnet-base-v2')\n",
    "    print(\"Default 'all-mpnet-base-v2' model loaded.\")\n",
    "\n",
    "print(\"\\nInitializing Pinecone client...\")\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Define the index name directly since it's not in .env\n",
    "INDEX_NAME = \"owasp-chatbot-index\"\n",
    "\n",
    "try:\n",
    "    print(f\"\\nConnecting to Pinecone index: {INDEX_NAME}\")\n",
    "    \n",
    "    # List all indexes for debugging\n",
    "    print(\"\\nAvailable indexes in your project:\")\n",
    "    indexes = pc.list_indexes()\n",
    "    index_names = [index.name for index in indexes]\n",
    "    print(index_names)\n",
    "    \n",
    "    # Check if index exists\n",
    "    if INDEX_NAME not in index_names:\n",
    "        raise ValueError(f\"Index '{INDEX_NAME}' not found. Available indexes: {index_names}\")\n",
    "    \n",
    "    # Connect to the index\n",
    "    pinecone_index = pc.Index(INDEX_NAME)\n",
    "    \n",
    "    # Verify connection by getting stats\n",
    "    try:\n",
    "        stats = pinecone_index.describe_index_stats()\n",
    "        print(f\"\\nSuccessfully connected to index: {INDEX_NAME}\")\n",
    "        print(f\"Index stats: {stats.dimension} dimensions, {stats.total_vector_count} vectors\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nWarning: Connected to index but could not retrieve stats: {e}\")\n",
    "        print(\"The index might be initializing. Waiting 10 seconds and retrying...\")\n",
    "        time.sleep(10)\n",
    "        stats = pinecone_index.describe_index_stats()\n",
    "        print(f\"Retry successful! Index stats: {stats.dimension} dimensions, {stats.total_vector_count} vectors\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nERROR: Failed to connect to Pinecone index '{INDEX_NAME}'\")\n",
    "    print(f\"Reason: {str(e)}\")\n",
    "    print(\"\\nTroubleshooting steps:\")\n",
    "    print(\"1. Verify the index name is correct (case-sensitive)\")\n",
    "    print(\"2. Check your Pinecone dashboard to confirm the index exists\")\n",
    "    print(\"3. Ensure your API key has permissions to access the index\")\n",
    "    print(\"4. Try accessing the index directly with: pc.Index('owasp-chatbot-index')\")\n",
    "    raise\n",
    "\n",
    "print(\"\\nPinecone connection established successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "552f69af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Define keyword extraction and query expansion functions\n",
    "\n",
    "def extract_keywords(text):\n",
    "    \"\"\"Extract important keywords from text for query expansion.\"\"\"\n",
    "    stopwords = {\"a\", \"an\", \"the\", \"and\", \"or\", \"but\", \"if\", \"then\", \"else\", \"when\", \n",
    "                \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \n",
    "                \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \n",
    "                \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \n",
    "                \"further\", \"then\", \"once\", \"here\", \"there\", \"all\", \"any\", \"both\", \n",
    "                \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \n",
    "                \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"can\", \n",
    "                \"will\", \"just\", \"should\", \"now\", \"what\", \"which\", \"how\", \"where\", \"is\", \"are\"}\n",
    "    \n",
    "    security_terms = {\"vulnerability\", \"exploit\", \"cve\", \"attack\", \"threat\", \"risk\", \n",
    "                     \"compromise\", \"security\", \"breach\", \"patch\", \"fix\", \"update\", \n",
    "                     \"mitigation\", \"remediation\", \"severity\", \"impact\", \"unauthorized\", \n",
    "                     \"access\", \"disclosure\", \"injection\", \"overflow\", \"credentials\"}\n",
    "    \n",
    "    stopwords = stopwords - security_terms\n",
    "    \n",
    "    words = text.lower().split()\n",
    "    important_words = [word for word in words if word not in stopwords and len(word) > 2]\n",
    "    \n",
    "    word_counts = Counter(important_words)\n",
    "    keywords = [word for word, count in word_counts.most_common(7)]\n",
    "    \n",
    "    all_keywords = list(set(important_words + keywords))\n",
    "    \n",
    "    return all_keywords\n",
    "\n",
    "def expand_query(question):\n",
    "    \"\"\"Generate multiple query variations to improve retrieval based on keywords and common patterns.\"\"\"\n",
    "    print(f\"  - Original query for expansion: '{question}'\")\n",
    "    keywords = extract_keywords(question)\n",
    "    \n",
    "    queries = [question]\n",
    "    \n",
    "    if len(keywords) > 0:\n",
    "        keyword_query = \" \".join(keywords)\n",
    "        if keyword_query.lower() != question.lower() and keyword_query not in queries:\n",
    "            queries.append(keyword_query)\n",
    "    \n",
    "    question_lower = question.lower()\n",
    "    for q_word in [\"what is \", \"what does \", \"how to \", \"how do i \", \"tell me about \", \"explain \"]:\n",
    "        if question_lower.startswith(q_word):\n",
    "            clean_q = question[len(q_word):].strip()\n",
    "            if clean_q and clean_q.lower() not in [q.lower() for q in queries]:\n",
    "                queries.append(clean_q)\n",
    "    \n",
    "    if any(term in question_lower for term in [\"vulnerability\", \"security\", \"risk\", \"threat\", \"issue\"]):\n",
    "        if \"fix\" in question_lower or \"remediation\" in question_lower or \"solution\" in question_lower:\n",
    "            if \"how to fix\" not in question_lower and \"remediation steps\" not in question_lower:\n",
    "                queries.append(f\"how to fix {question_lower}\")\n",
    "                queries.append(f\"remediation steps for {question_lower}\")\n",
    "        if \"prevent\" in question_lower or \"avoid\" in question_lower:\n",
    "            queries.append(f\"prevent {question_lower}\")\n",
    "        if \"detect\" in question_lower or \"find\" in question_lower:\n",
    "            queries.append(f\"detect {question_lower}\")\n",
    "\n",
    "    unique_queries = list(dict.fromkeys(queries))\n",
    "    \n",
    "    print(f\"  - Expanded queries ({len(unique_queries)}):\")\n",
    "    for i, q in enumerate(unique_queries):\n",
    "        print(f\"    {i+1}. {q}\")\n",
    "    \n",
    "    return unique_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ffe2d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Define the find_answer_from_pinecone function (MODIFIED for context)\n",
    "\n",
    "def find_answer_from_pinecone(user_query, pinecone_index, model, chat_history=[], top_k_per_query=3, final_top_k=1, similarity_threshold=0.6):\n",
    "    \"\"\"\n",
    "    Finds the most semantically similar question in Pinecone, retrieving from expanded queries,\n",
    "    and includes proactive suggestions if available. Now incorporates chat history for context.\n",
    "    \n",
    "    Args:\n",
    "        user_query (str): The current question asked by the user.\n",
    "        pinecone_index (Pinecone.Index): The initialized Pinecone index.\n",
    "        model (SentenceTransformer): The loaded (fine-tuned) BERT model.\n",
    "        chat_history (list): A list of recent (user, bot) conversation turns.\n",
    "        top_k_per_query (int): Number of top results to retrieve for each expanded query.\n",
    "        final_top_k (int): Number of overall best results to consider.\n",
    "        similarity_threshold (float): Minimum similarity score to consider a match valid.\n",
    "\n",
    "    Returns:\n",
    "        str: The answer to the most similar question, or a fallback message if no good match is found.\n",
    "    \"\"\"\n",
    "    if not user_query:\n",
    "        return \"Please type a question to get started!\"\n",
    "\n",
    "    # 1. Contextualize the user query\n",
    "    contextual_query = user_query\n",
    "    if chat_history:\n",
    "        # Combine the last few turns of conversation to provide context for the current query.\n",
    "        # We limit the history to avoid making the query too long for BERT.\n",
    "        # Format: \"(user: user_message) (bot: bot_response) current_user_query\"\n",
    "        recent_history_parts = []\n",
    "        for sender, message in chat_history[-4:]: # Consider last 2 user turns and 2 bot turns (4 items total)\n",
    "            # Shorten message if very long to prevent input token limits\n",
    "            short_message = message[:100] + \"...\" if len(message) > 100 else message\n",
    "            recent_history_parts.append(f\"({sender}: {short_message})\")\n",
    "        \n",
    "        contextual_query = f\"{' '.join(recent_history_parts)} {user_query}\"\n",
    "        print(f\"\\n--- Contextualized Query (with history): '{contextual_query}' ---\")\n",
    "\n",
    "    # 2. Expand the contextualized query\n",
    "    expanded_queries = expand_query(contextual_query) # Use contextual_query for expansion\n",
    "    \n",
    "    all_query_results = []\n",
    "\n",
    "    # 3. Generate embeddings and query Pinecone for each expanded query\n",
    "    for query_text in expanded_queries:\n",
    "        query_embedding = model.encode(query_text).tolist()\n",
    "        try:\n",
    "            results = pinecone_index.query(\n",
    "                vector=query_embedding,\n",
    "                top_k=top_k_per_query,\n",
    "                include_metadata=True\n",
    "            )\n",
    "            all_query_results.extend(results.matches)\n",
    "        except Exception as e:\n",
    "            print(f\"Error querying Pinecone with expanded query '{query_text}': {e}\")\n",
    "\n",
    "    if not all_query_results:\n",
    "        return \"Sorry, I'm having trouble retrieving information from my knowledge base right now, or no results were found for any query variations.\"\n",
    "\n",
    "    # 4. Consolidate and rank all results from expanded queries\n",
    "    all_query_results.sort(key=lambda x: x.score, reverse=True)\n",
    "    \n",
    "    unique_results = []\n",
    "    seen_ids = set()\n",
    "    for match in all_query_results:\n",
    "        original_id = match.metadata.get('id_original')\n",
    "        if original_id and original_id not in seen_ids:\n",
    "            unique_results.append(match)\n",
    "            seen_ids.add(original_id)\n",
    "    \n",
    "    if not unique_results:\n",
    "        return \"I couldn't find any relevant information for your query in the knowledge base after trying multiple approaches.\"\n",
    "\n",
    "    best_match = unique_results[0]\n",
    "    best_score = best_match.score\n",
    "    \n",
    "    matched_question = best_match.metadata.get('question', 'N/A')\n",
    "    matched_answer = best_match.metadata.get('answer', 'N/A')\n",
    "    related_topics = best_match.metadata.get('related_topics', [])\n",
    "\n",
    "    print(f\"\\n--- Debug Info ---\")\n",
    "    print(f\"Original user query: '{user_query}'\")\n",
    "    print(f\"Contextualized query used for search: '{contextual_query}'\") # Show the actual query used for search\n",
    "    print(f\"Overall best matched question (from Pinecone): '{matched_question}'\")\n",
    "    print(f\"Overall best similarity score: {best_score:.4f} (Threshold: {similarity_threshold})\")\n",
    "    print(f\"Related topics found: {related_topics}\")\n",
    "    print(f\"--- End Debug Info ---\\n\")\n",
    "\n",
    "    response_text = \"\"\n",
    "    if best_score >= similarity_threshold:\n",
    "        response_text = matched_answer\n",
    "        \n",
    "        if related_topics:\n",
    "            response_text += \"\\n\\n**You might also be interested in:**\\n\"\n",
    "            for topic in related_topics:\n",
    "                response_text += f\"- {topic}\\n\"\n",
    "    else:\n",
    "        response_text = (f\"I'm sorry, I couldn't find a direct answer to '{user_query}' \"\n",
    "                         f\"in my knowledge base. The closest match I found was \"\n",
    "                         f\"'{matched_question}' with a similarity score of {best_score:.2f}. \"\n",
    "                         f\"Perhaps try rephrasing your question or asking about a more specific OWASP Top 10 topic.\")\n",
    "    \n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6d77a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Define the question segmentation function (MODIFIED to use NLTK)\n",
    "\n",
    "def segment_questions(user_input):\n",
    "    \"\"\"\n",
    "    Segments a user's multi-question input into individual sentences/questions using NLTK.\n",
    "    Requires 'punkt' tokenizer to be downloaded (nltk.download('punkt')).\n",
    "    \"\"\"\n",
    "    if not user_input.strip():\n",
    "        return []\n",
    "\n",
    "    # Use NLTK's sentence tokenizer for more robust segmentation\n",
    "    # It handles various punctuation and sentence structures better than simple regex.\n",
    "    sentences = nltk.sent_tokenize(user_input)\n",
    "    \n",
    "    # Filter out empty strings and strip whitespace from each segmented sentence\n",
    "    final_questions = [q.strip() for q in sentences if q.strip()]\n",
    "    \n",
    "    # Fallback: if NLTK fails to segment (e.g., if punkt not downloaded or unusual input),\n",
    "    # revert to a simpler regex-based or single-question approach.\n",
    "    if not final_questions:\n",
    "        # Original regex-based segmentation (kept for robustness if NLTK isn't available/working)\n",
    "        segments_regex = re.split(r'(\\?|\\!|\\.|\\band\\b|\\bor\\b)', user_input, flags=re.IGNORECASE)\n",
    "        temp_questions = []\n",
    "        current_q_part = \"\"\n",
    "        for i, segment in enumerate(segments_regex):\n",
    "            segment = segment.strip()\n",
    "            if not segment: continue\n",
    "            is_delimiter = False\n",
    "            if segment in ['?', '!', '.'] or segment.lower() in ['and', 'or']: is_delimiter = True\n",
    "            if is_delimiter:\n",
    "                if current_q_part:\n",
    "                    if segment in ['?', '!', '.']: current_q_part += segment\n",
    "                    temp_questions.append(current_q_part.strip())\n",
    "                    current_q_part = \"\"\n",
    "            else:\n",
    "                if current_q_part: current_q_part += \" \"\n",
    "                current_q_part += segment\n",
    "        if current_q_part: temp_questions.append(current_q_part.strip())\n",
    "        \n",
    "        final_questions = [q for q in temp_questions if q]\n",
    "        \n",
    "    # If still no questions, return the original input as a single question\n",
    "    if not final_questions and user_input.strip():\n",
    "        final_questions = [user_input.strip()]\n",
    "\n",
    "    return final_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a01ccb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Main Chatbot Backend...\n",
      "\n",
      "=======================================================\n",
      "   OWASP Top 10 Chatbot Ready for Interaction! \n",
      "=======================================================\n",
      "Type your questions about OWASP vulnerabilities (e.g., 'What is injection?').\n",
      "You can now ask follow-up questions like 'How to prevent that?'\n",
      "Type 'exit' or 'quit' to end the session.\n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "--- Contextualized Query (with history): '(user: \"If my system's internal configuration files are accessible through a web browser, what vulnerabilit...) \"If my system's internal configuration files are accessible through a web browser, what vulnerability applies?\"' ---\n",
      "  - Original query for expansion: '(user: \"If my system's internal configuration files are accessible through a web browser, what vulnerabilit...) \"If my system's internal configuration files are accessible through a web browser, what vulnerability applies?\"'\n",
      "  - Expanded queries (2):\n",
      "    1. (user: \"If my system's internal configuration files are accessible through a web browser, what vulnerabilit...) \"If my system's internal configuration files are accessible through a web browser, what vulnerability applies?\"\n",
      "    2. system's (user: vulnerabilit...) accessible vulnerability browser, configuration \"if applies?\" web internal files\n",
      "\n",
      "--- Debug Info ---\n",
      "Original user query: '\"If my system's internal configuration files are accessible through a web browser, what vulnerability applies?\"'\n",
      "Contextualized query used for search: '(user: \"If my system's internal configuration files are accessible through a web browser, what vulnerabilit...) \"If my system's internal configuration files are accessible through a web browser, what vulnerability applies?\"'\n",
      "Overall best matched question (from Pinecone): 'How can you detect if directory listing is enabled on a web server?'\n",
      "Overall best similarity score: 0.4553 (Threshold: 0.6)\n",
      "Related topics found: []\n",
      "--- End Debug Info ---\n",
      "\n",
      "Bot: I'm sorry, I couldn't find a direct answer to '\"If my system's internal configuration files are accessible through a web browser, what vulnerability applies?\"' in my knowledge base. The closest match I found was 'How can you detect if directory listing is enabled on a web server?' with a similarity score of 0.46. Perhaps try rephrasing your question or asking about a more specific OWASP Top 10 topic.\n",
      "\n",
      "\n",
      "--- Contextualized Query (with history): '(user: \"If my system's internal configuration files are accessible through a web browser, what vulnerabilit...) (bot: I'm sorry, I couldn't find a direct answer to '\"If my system's internal configuration files are acce...) (user: \"What architectural patterns help mitigate insecure design choices early in development?) \"What architectural patterns help mitigate insecure design choices early in development?' ---\n",
      "  - Original query for expansion: '(user: \"If my system's internal configuration files are accessible through a web browser, what vulnerabilit...) (bot: I'm sorry, I couldn't find a direct answer to '\"If my system's internal configuration files are acce...) (user: \"What architectural patterns help mitigate insecure design choices early in development?) \"What architectural patterns help mitigate insecure design choices early in development?'\n",
      "  - Expanded queries (2):\n",
      "    1. (user: \"If my system's internal configuration files are accessible through a web browser, what vulnerabilit...) (bot: I'm sorry, I couldn't find a direct answer to '\"If my system's internal configuration files are acce...) (user: \"What architectural patterns help mitigate insecure design choices early in development?) \"What architectural patterns help mitigate insecure design choices early in development?\n",
      "    2. development?) couldn't direct acce...) sorry, \"if design system's (user: accessible patterns \"what browser, configuration answer i'm find (bot: architectural mitigate insecure web internal files vulnerabilit...) early development? choices help '\"if\n",
      "\n",
      "--- Debug Info ---\n",
      "Original user query: '\"What architectural patterns help mitigate insecure design choices early in development?'\n",
      "Contextualized query used for search: '(user: \"If my system's internal configuration files are accessible through a web browser, what vulnerabilit...) (bot: I'm sorry, I couldn't find a direct answer to '\"If my system's internal configuration files are acce...) (user: \"What architectural patterns help mitigate insecure design choices early in development?) \"What architectural patterns help mitigate insecure design choices early in development?'\n",
      "Overall best matched question (from Pinecone): 'What types of user inputs can lead to SSRF vulnerabilities?'\n",
      "Overall best similarity score: 0.4669 (Threshold: 0.6)\n",
      "Related topics found: ['What specific input validation failures lead to SSRF vulnerabilities? (A10-T2)', 'Which types of application input fields should be checked for SSRF vulnerabilities? (A10-V6)']\n",
      "--- End Debug Info ---\n",
      "\n",
      "Bot: I'm sorry, I couldn't find a direct answer to '\"What architectural patterns help mitigate insecure design choices early in development?' in my knowledge base. The closest match I found was 'What types of user inputs can lead to SSRF vulnerabilities?' with a similarity score of 0.47. Perhaps try rephrasing your question or asking about a more specific OWASP Top 10 topic.\n",
      "\n",
      "Bot: Goodbye! Stay secure.\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Main Execution - Connect to Pinecone and Start Chatbot\n",
    "\n",
    "print(\"Starting Main Chatbot Backend...\")\n",
    "\n",
    "print(\"\\n=======================================================\")\n",
    "print(\"   OWASP Top 10 Chatbot Ready for Interaction! \")\n",
    "print(\"=======================================================\")\n",
    "print(\"Type your questions about OWASP vulnerabilities (e.g., 'What is injection?').\")\n",
    "print(\"You can now ask follow-up questions like 'How to prevent that?'\")\n",
    "print(\"Type 'exit' or 'quit' to end the session.\")\n",
    "print(\"-------------------------------------------------------\\n\")\n",
    "\n",
    "# --- Initialize chat history ---\n",
    "chat_history = [] # Stores (sender, message) tuples, typically (role, text)\n",
    "\n",
    "# --- Start the interactive chatbot session ---\n",
    "while True:\n",
    "    user_input = input(\"You: \").strip()\n",
    "    \n",
    "    if user_input.lower() in ['exit', 'quit']:\n",
    "        print(\"Bot: Goodbye! Stay secure.\")\n",
    "        break\n",
    "    \n",
    "    if not user_input:\n",
    "        print(\"Bot: Please enter a question.\")\n",
    "        continue\n",
    "\n",
    "    # Add user's raw input to history *before* segmentation for full context\n",
    "    chat_history.append((\"user\", user_input))\n",
    "\n",
    "    # Segment the user's input into individual questions\n",
    "    # NLTK's sent_tokenize is now the primary method\n",
    "    questions = segment_questions(user_input)\n",
    "    \n",
    "    if not questions:\n",
    "        print(\"Bot: I didn't detect any valid questions in your input. Please try again.\")\n",
    "        # Remove the last user input from history if no valid questions were found\n",
    "        if chat_history and chat_history[-1][0] == \"user\":\n",
    "            chat_history.pop()\n",
    "        continue\n",
    "\n",
    "    full_response_parts = []\n",
    "    # Loop through each segmented question to get an individual response\n",
    "    for i, q in enumerate(questions):\n",
    "        # Pass the current chat_history to the find_answer_from_pinecone function for context\n",
    "        individual_response = find_answer_from_pinecone(q, pinecone_index, model, chat_history=chat_history)\n",
    "        \n",
    "        if len(questions) > 1:\n",
    "            full_response_parts.append(f\"**Question {i+1}:** _{q}_\") # Markdown for bold and italics\n",
    "            full_response_parts.append(individual_response)\n",
    "            full_response_parts.append(\"\\n---\") # Separator between answers\n",
    "        else:\n",
    "            full_response_parts.append(individual_response) # For single questions, no prefix needed\n",
    "\n",
    "    # Join all individual responses into a single output\n",
    "    final_bot_response = \"\\n\".join(full_response_parts).strip()\n",
    "    # Remove trailing separator if it's the last one in the list\n",
    "    if final_bot_response.endswith(\"\\n---\"):\n",
    "        final_bot_response = final_bot_response[:-4].strip()\n",
    "    elif final_bot_response.endswith(\"---\"):\n",
    "        final_bot_response = final_bot_response[:-3].strip()\n",
    "\n",
    "    print(f\"Bot: {final_bot_response}\\n\")\n",
    "    \n",
    "    # Add the bot's final combined response for this turn to history\n",
    "    chat_history.append((\"bot\", final_bot_response))\n",
    "\n",
    "    # Optional: Limit chat history to a few turns to prevent it from growing too large\n",
    "    # and to keep context relevant to recent interactions.\n",
    "    # Keep last 2 user messages and 2 bot responses (total 4 elements in history)\n",
    "    max_history_elements = 4 \n",
    "    if len(chat_history) > max_history_elements:\n",
    "        chat_history = chat_history[-max_history_elements:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d9f97b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot-env",
   "language": "python",
   "name": "chatbot-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
