{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9096f1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76108f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd796bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "owasp_category_map = {\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A01_2021.json': 'A01:2021 – Broken Access Control',\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A02_2021.json': 'A02:2021 – Cryptographic Failures',\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A03_2021.json': 'A03:2021 – Injection',\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A04_2021.json': 'A04:2021 – Insecure Design',\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A05_2021.json': 'A05:2021 – Security Misconfigurationn',\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A06_2021.json': 'A06:2021 – Vulnerable and Outdated Components',\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A07_2021.json': 'A07:2021 – Identification and Authentication Failures',\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A08_2021.json': 'A08:2021 – Software and Data Integrity Failures',\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A09_2021.json': 'A09:2021 – Security Logging and Monitoring Failures',\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A10_2021.json': 'A10:2021 – Server-Side Request Forgery (SSRF)',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f77c1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Load and Parse JSON Data (using the robust function from Stage 2)\n",
    "def load_json_data_for_qa(file_paths, owasp_map):\n",
    "    \"\"\"\n",
    "    Loads and parses JSON files, recursively extracting 'question', 'answer',\n",
    "    'id', 'intent', 'type', 'related_topics', and now 'owasp_category'.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "\n",
    "    def extract_qa_items(obj, current_file_name):\n",
    "        if isinstance(obj, dict):\n",
    "            # Check for the core Q&A fields\n",
    "            if 'question' in obj and 'answer' in obj:\n",
    "                item = {\n",
    "                    'question': obj['question'],\n",
    "                    'answer': obj['answer'],\n",
    "                    'id': obj.get('id', None),\n",
    "                    'intent': obj.get('intent', None),\n",
    "                    'type': obj.get('type', None),\n",
    "                    'related_topics': obj.get('related_topics', []),\n",
    "                    'owasp_category': owasp_map.get(current_file_name, 'General') # Assign OWASP category\n",
    "                }\n",
    "                all_data.append(item)\n",
    "            # Recurse into dictionary values\n",
    "            for key, value in obj.items():\n",
    "                extract_qa_items(value, current_file_name)\n",
    "        elif isinstance(obj, list):\n",
    "            # Recurse into list elements\n",
    "            for item in obj:\n",
    "                extract_qa_items(item, current_file_name)\n",
    "\n",
    "    # Use file_files from the global scope of the Jupyter environment if available\n",
    "    global file_files\n",
    "    \n",
    "    for file_path in file_files:\n",
    "        try:\n",
    "            # Use content_fetcher to get file content (CRUCIAL for this environment)\n",
    "            content = content_fetcher.fetch(source_references=[{\"id\": file_path, \"type\": \"uploaded\"}])\n",
    "            data = json.loads(content)\n",
    "            \n",
    "            # Extract just the filename from the path (e.g., 'A01_2021.json')\n",
    "            current_file_name = os.path.basename(file_path)\n",
    "            \n",
    "            extract_qa_items(data, current_file_name)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: {file_path} not found.\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error: Could not decode JSON from {file_path}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred while processing {file_path}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "\n",
    "    # Define file paths (ensure these match your uploaded JSONs)\n",
    "file_paths = [\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A01_2021.json',\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A02_2021.json',\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A03_2021.json',\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A04_2021.json',\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A05_2021.json',\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A06_2021.json',\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A07_2021.json',\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A08_2021.json',\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A09_2021.json',\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A10_2021.json'\n",
    "] \n",
    "\n",
    "\n",
    "# Load data into a DataFrame\n",
    "df_qa = load_json_data_for_qa(file_paths, owasp_category_map) # Pass owasp_category_map\n",
    "\n",
    "if df_qa.empty:\n",
    "    print(\"No Q&A data loaded for Pinecone. Please ensure JSON files are correct and present.\")\n",
    "    exit()\n",
    "\n",
    "# Drop rows with missing essential information for embeddings/Pinecone\n",
    "# Ensure 'owasp_category' is also checked\n",
    "df_qa.dropna(subset=['question', 'answer', 'id', 'type', 'owasp_category'], inplace=True)\n",
    "print(f\"Loaded and filtered {len(df_qa)} Q&A entries for Pinecone indexing.\")\n",
    "print(\"\\nDataFrame Head:\")\n",
    "print(df_qa.head())\n",
    "print(f\"\\nUnique OWASP Categories (for namespaces): {df_qa['owasp_category'].nunique()}\")\n",
    "print(df_qa['owasp_category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab5f0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Initialize Pinecone\n",
    "# IMPORTANT: Replace with your actual Pinecone API Key and Environment\n",
    "# You can find these in your Pinecone dashboard: https://app.pinecone.io/\n",
    "PINECONE_API_KEY = \"YOUR_API_KEY\" # Replace with your Pinecone API Key\n",
    "PINECONE_ENVIRONMENT = \"YOUR_ENVIRONMENT\" # Replace with your Pinecone environment (e.g., \"us-east-1\" or \"gcp-starter\")\n",
    "\n",
    "if PINECONE_API_KEY == \"YOUR_API_KEY\" or PINECONE_ENVIRONMENT == \"YOUR_ENVIRONMENT\":\n",
    "    print(\"\\nWARNING: Please replace 'YOUR_API_KEY' and 'YOUR_ENVIRONMENT' with your actual Pinecone credentials.\")\n",
    "    # For demonstration, we'll proceed, but index creation/upsert will fail without valid credentials.\n",
    "    # exit() # Uncomment to stop execution if credentials are not set\n",
    "\n",
    "try:\n",
    "    pc = Pinecone(api_key=PINECONE_API_KEY, environment=PINECONE_ENVIRONMENT)\n",
    "    print(\"\\nPinecone initialized successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Pinecone: {e}\")\n",
    "    print(\"Please check your API key, environment, and network connectivity.\")\n",
    "    # exit() # Uncomment to stop execution if Pinecone initialization fails\n",
    "\n",
    "\n",
    "# Define Pinecone index details\n",
    "index_name = \"security-qa-chatbot\"\n",
    "dimension = 768 # all-mpnet-base-v2 embeddings are 768-dimensional\n",
    "metric = \"cosine\" # Cosine similarity is standard for sentence embeddings\n",
    "\n",
    "# Check if index exists, create if not\n",
    "if index_name not in pc.list_indexes():\n",
    "    print(f\"Creating new Pinecone index: {index_name}...\")\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=dimension,\n",
    "        metric=metric,\n",
    "        spec=ServerlessSpec(cloud='aws', region='us-west-2') # Example spec, adjust region/cloud as needed\n",
    "    )\n",
    "    print(f\"Index '{index_name}' created.\")\n",
    "else:\n",
    "    print(f\"Index '{index_name}' already exists.\")\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "print(f\"Pinecone index info: {index.describe_index_stats()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5151e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Load Semantic Model (from Stage 2)\n",
    "# Ensure you have the fine_tuned_semantic_model directory from Stage 2 run\n",
    "semantic_model_path = \"./fine_tuned_semantic_model\"\n",
    "if not os.path.exists(semantic_model_path):\n",
    "    print(f\"\\nError: Fine-tuned semantic model not found at '{semantic_model_path}'.\")\n",
    "    print(\"Please ensure Stage 2 (Semantic Search Embedding Fine-tuning) was run successfully and saved the model.\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    semantic_model = SentenceTransformer(semantic_model_path)\n",
    "    semantic_model.to(device) # Move model to GPU\n",
    "    print(f\"\\nSemantic embedding model loaded successfully from {semantic_model_path}.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading semantic model: {e}\")\n",
    "    print(\"Ensure 'sentence-transformers' library is correctly installed and the model path is valid.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514f70db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Prepare Data for Indexing & Generate Embeddings\n",
    "# We'll create embeddings for a combination of question and answer for richer retrieval context.\n",
    "# Each vector in Pinecone needs a unique ID and optional metadata.\n",
    "# We'll use the 'id' from your JSON data as the vector ID.\n",
    "# Metadata will include 'question', 'answer', 'intent', 'type', 'related_topics', and 'owasp_category'.\n",
    "\n",
    "vectors_to_upsert = []\n",
    "batch_size = 100 # Adjust batch size for upserting to Pinecone (max 100 per call)\n",
    "max_text_length = 512 # Limit length of text for embedding to avoid truncation issues\n",
    "\n",
    "print(\"\\nGenerating embeddings and preparing data for Pinecone upsert...\")\n",
    "# Iterate through DataFrame in batches\n",
    "for i in range(0, len(df_qa), batch_size):\n",
    "    batch_df = df_qa.iloc[i : i + batch_size]\n",
    "    \n",
    "    # Prepare texts for embedding\n",
    "    # Concatenate question and answer for a rich embedding context\n",
    "    texts_to_embed = []\n",
    "    for _, row in batch_df.iterrows():\n",
    "        combined_text = f\"question: {row['question']} answer: {row['answer']}\"\n",
    "        texts_to_embed.append(combined_text[:max_text_length]) \n",
    "\n",
    "    # Generate embeddings for the batch\n",
    "    batch_embeddings = semantic_model.encode(texts_to_embed, convert_to_tensor=True, device=device).tolist()\n",
    "\n",
    "    # Prepare vectors for upsert\n",
    "    for idx, row in batch_df.iterrows():\n",
    "        vector_id = str(row['id']) # Ensure ID is string\n",
    "        embedding = batch_embeddings[idx - i] # Get corresponding embedding for the row\n",
    "        \n",
    "        # Prepare metadata\n",
    "        metadata = {\n",
    "            \"question\": row['question'],\n",
    "            \"answer\": row['answer'],\n",
    "            \"intent\": row['intent'],\n",
    "            \"type\": row['type'],\n",
    "            \"related_topics\": row['related_topics'],\n",
    "            \"owasp_category\": row['owasp_category'] # Added owasp_category to metadata\n",
    "        }\n",
    "        \n",
    "        vectors_to_upsert.append({\n",
    "            \"id\": vector_id,\n",
    "            \"values\": embedding,\n",
    "            \"metadata\": metadata\n",
    "        })\n",
    "\n",
    "print(f\"Prepared {len(vectors_to_upsert)} vectors for upsert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c4181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Upsert to Pinecone Index with Namespaces\n",
    "# Pinecone allows namespaces to logically partition an index.\n",
    "# We will now use the 'owasp_category' field as namespaces.\n",
    "\n",
    "vectors_by_namespace = {}\n",
    "for vec in vectors_to_upsert:\n",
    "    # Use owasp_category for namespace\n",
    "    vec_namespace = vec['metadata']['owasp_category'] \n",
    "    if vec_namespace not in vectors_by_namespace:\n",
    "        vectors_by_namespace[vec_namespace] = []\n",
    "    vectors_by_namespace[vec_namespace].append(vec)\n",
    "\n",
    "print(\"\\nUpserting vectors to Pinecone index with OWASP categories as namespaces...\")\n",
    "upsert_batch_size = 100 # Pinecone recommended batch size for upsert\n",
    "\n",
    "for namespace, vectors in vectors_by_namespace.items():\n",
    "    print(f\"Upserting {len(vectors)} vectors to namespace: '{namespace}'\")\n",
    "    for i in range(0, len(vectors), upsert_batch_size):\n",
    "        batch = vectors[i : i + upsert_batch_size]\n",
    "        try:\n",
    "            index.upsert(vectors=batch, namespace=namespace)\n",
    "        except Exception as e:\n",
    "            print(f\"Error during upsert to namespace '{namespace}': {e}\")\n",
    "            # Continue or handle error as needed\n",
    "\n",
    "print(\"\\nPinecone upsert complete.\")\n",
    "print(f\"Final index stats after upsert: {index.describe_index_stats()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d6dd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Test Retrieval (Basic Semantic Search Query)\n",
    "print(\"\\n--- Testing Basic Pinecone Retrieval ---\")\n",
    "\n",
    "# Example query to test retrieval\n",
    "query_text = \"How can I prevent unauthorized access in my web application?\"\n",
    "# Use a specific OWASP category namespace for targeted search\n",
    "query_namespace = 'A01:2021 – Broken Access Control' # Example namespace\n",
    "\n",
    "# Generate embedding for the query using the semantic model\n",
    "query_embedding = semantic_model.encode(query_text, convert_to_tensor=True, device=device).tolist()\n",
    "\n",
    "try:\n",
    "    print(f\"\\nQuerying Pinecone in namespace '{query_namespace}' for: \\\"{query_text}\\\"\")\n",
    "    query_results = index.query(\n",
    "        vector=query_embedding,\n",
    "        top_k=5, # Retrieve top 5 most similar results\n",
    "        include_metadata=True, # Important to get back question, answer, etc.\n",
    "        namespace=query_namespace # Querying a specific namespace\n",
    "    )\n",
    "\n",
    "    print(\"\\nTop 5 Retrieved Results:\")\n",
    "    for i, match in enumerate(query_results.matches):\n",
    "        print(f\"\\n--- Result {i+1} ---\")\n",
    "        print(f\"Score: {match.score:.4f}\")\n",
    "        print(f\"Vector ID: {match.id}\")\n",
    "        if match.metadata:\n",
    "            print(f\"Question: {match.metadata.get('question', 'N/A')}\")\n",
    "            print(f\"Answer: {match.metadata.get('answer', 'N/A')[:100]}...\") # Truncate answer\n",
    "            print(f\"Intent: {match.metadata.get('intent', 'N/A')}\")\n",
    "            print(f\"Type: {match.metadata.get('type', 'N/A')}\")\n",
    "            print(f\"OWASP Category: {match.metadata.get('owasp_category', 'N/A')}\") # Display OWASP category\n",
    "            print(f\"Related Topics: {match.metadata.get('related_topics', 'N/A')}\")\n",
    "        else:\n",
    "            print(\"No metadata found.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during Pinecone query: {e}\")\n",
    "    print(\"Please ensure your Pinecone index is active and correctly configured.\")\n",
    "\n",
    "\n",
    "print(\"\\nStage 4: Embedding and Pinecone indexing complete with OWASP categories as namespaces.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
